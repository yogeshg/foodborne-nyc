 * quantify trigrams > bigrams
 * improve the dense architecture
   -> 4-grams, 5, ...?
 * correct data
 * database
 * validation mertric
 * 

 * Hidden layer at the wrong place, after conv layer
 * over flowing logsumexp
 * api changes
 * change the function for getting data
 


TODOs from the meeting:

<!-- 1. Switch to the correct data splits -->
<!-- 2. Add dropout to word embeddings, convs -->
<!-- 3. Correct logsumexp implementation -->
<!-- 4. Switch to AUC metric -->
<!-- 5. Add in git commit and save commit hash before each experiment -->
<!-- 6. Use less training epochs (probably 300 at most, if I recall correctly from the plots) -->

7. Try regularizations at .001 and .0001
8. Quantify logsumexp vs max pooling
9. Quantify (1-5)-grams on performance
10. Quantify using 5, 10, 20, 50 filters

11. Implement back-tracable model to look into meaningful activations
<!-- 12. Change API - Convolutional1D->Conv1D and params, nb_epoch->epochs, merge->concat -->
13. Add parameter for git commit and number of epochs
14. Move functions according to their classification as per Keras
<!-- 15. add constants, like val_auc -->
<!-- 16. Validate data should be given by ratio -->
sanity check?


## logsumexp - effect of regularization
* file:///tmp/archive/view-logsumexp_5_2.html

5, 50
pooling : logsumexp vs max pooling
regularization : 0.001, 0

5, 50
lr = half
upto 5 filters
