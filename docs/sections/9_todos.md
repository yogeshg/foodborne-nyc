# Todos

1. Tasks &  Description
    - number of train & test samples
    - label distribution
    - hist of doc lengths
    - vocab sizes
2. Twitter Baseline Results
    - Table of numbers
    - Best Baselines
    - Some choice (^) figure
    - "refer to notebook.pdf for fall results / figs" & also link to Yelp paper
3. NN
    - Word embeddings & unseen words via word2vec (mention Glove)
    - Describe CNN (+Math def)
    - Analogy to soft ngrams as motivation
    - Gets around sparsity -> larger n possible
    - Dropout & weight decay & Early stopping = Regularisation
4. HP search & Train / Eval Metrics:
    - Metrics -> see "metrics_derivations.pdf" (in Appendix)
    - HP search space (Grid Search in Fall)
        + Mention invalidated Spring experiments
    - Best resulting Model hyperparameters
    - Grid Results table & interpretation
5. Official Tests of Best Biased, Gold, Silver for Yelp & Twitter
    - Just like baseline results
6. Model inspection
    - Intuition & formula
    - Confusion matrix examples (see (4)) from todos
7. Conclusion


